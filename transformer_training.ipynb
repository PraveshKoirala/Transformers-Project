{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOKNFx1ZGbdgEM9JEwhMDPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PraveshKoirala/Transformers-Project/blob/main/transformer_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzHUcsV682OL",
        "outputId": "3cf89510-8a3f-4dc5-b02d-9bda96f2d959"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (57.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration parameters"
      ],
      "metadata": {
        "id": "Apk5smKo672t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_DvPsfm61n5",
        "outputId": "0e07928e-5c2e-44d7-de88-00f93eb70fab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ],
      "source": [
        "%%file config.py\n",
        "# Max number of tokens\n",
        "dmodel = 512\n",
        "dim_val = dmodel  # This can be any value divisible by n_heads. 512 is used in the original transformer paper.\n",
        "target_seq_len = 1  # Length of the target sequence, i.e. how many time steps should your forecast cover\n",
        "n_encoder_layers = 4  # Number of times the encoder layer is stacked in the encoder\n",
        "n_decoder_layers = 4  # Number of times the decoder layer is stacked in the decoder\n",
        "n_heads = 8  # The number of attention heads (aka parallel attention layers). dim_val must be divisible by this number\n",
        "batch_size = 512\n",
        "\n",
        "enc_seq_len = 5  # length of input given to encoder. Can have any integer value.\n",
        "dec_seq_len = enc_seq_len-1  # length of input given to decoder. Can have any integer value.\n",
        "max_seq_len = enc_seq_len  # What's the longest sequence the model will encounter? Used to make the positional encoder\n",
        "epochs = 20\n",
        "lr = 0.001\n",
        "weight_decay = 0.0001\n",
        "ratio = 0.8\n",
        "DEVICE = \"cuda\"\n",
        "TIME_EMBEDDING = 32\n",
        "SEGMENT_EMBEDDING = 128\n",
        "DAY_EMBEDDING = 7\n",
        "NUM_DAY = 7\n",
        "NUM_SEGMENTS = 50\n",
        "NUM_TIME=96\n",
        "NUM_CONTINUOUS=8\n",
        "dim_continuous = dmodel - TIME_EMBEDDING - SEGMENT_EMBEDDING - DAY_EMBEDDING"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets and Dataloader stuff"
      ],
      "metadata": {
        "id": "dmkE-SMl7E5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_prefix=\"/content/drive/MyDrive/Transformers/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6CprGTsFy5X",
        "outputId": "92a71f55-7c38-4f5e-99b3-750d0704c4cf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade pandas"
      ],
      "metadata": {
        "id": "-XO6ViaOF-84"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%file dataset.py\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import pandas as pd\n",
        "import config\n",
        "import numpy as np\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, buckets):\n",
        "        self.buckets=buckets\n",
        "        self.data = data\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        cols = self.data.iloc[self.buckets[item]]\n",
        "        return  torch.tensor(cols[['time_window', 'dayofweek', 'segment_id_int',\n",
        "                                   'is_holiday', 'is_school_break', \n",
        "                                   'travel_time', 'darksky_temperature',\n",
        "                                   'darksky_humidity', \n",
        "                                   'darksky_precipitation_probability',\n",
        "                                   'traffic_speed', 'distance_m']].astype(np.float).values), \\\n",
        "                torch.tensor(cols[['delay_time']].iloc[:config.max_seq_len-1].astype(np.float).values), \\\n",
        "                torch.tensor(cols[['delay_time']].iloc[config.max_seq_len-1].astype(np.float).values)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buckets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV7YKS5S7Eah",
        "outputId": "a2e38694-6252-49c6-9f29-cb2243d9b072"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file metrics.py\n",
        "import numpy as np\n",
        "\n",
        "def get_mape(x, y):\n",
        "    return np.mean(np.abs((x-y)/x)) * 100\n",
        "\n",
        "\n",
        "def get_rmse(x, y):\n",
        "    return np.sqrt(np.mean(np.square(x - y)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vd4Sda_A6_Ek",
        "outputId": "5684de04-8271-44f7-8138-9338a877fe04"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting metrics.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file penc.py\n",
        "import torch\n",
        "import math\n",
        "from torch import nn, Tensor\n",
        "\n",
        "\n",
        "class PositionalEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Adapted from:\n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    https://github.com/LiamMaclean216/Pytorch-Transfomer/blob/master/utils.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dropout: float = 0.1, max_seq_len: int = 5000, d_model: int = 512):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dropout: the dropout rate\n",
        "            max_seq_len: the maximum length of the input sequences\n",
        "            d_model: The dimension of the output of sub-layers in the model\n",
        "                     (Vaswani et al, 2017)\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Create constant positional encoding matrix with values\n",
        "        # dependent on position and i\n",
        "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
        "\n",
        "        exp_input = torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
        "\n",
        "        div_term = torch.exp(exp_input)  # Returns a new tensor with the exponential of the elements of exp_input\n",
        "\n",
        "        pe = torch.zeros(max_seq_len, d_model)\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)  # torch.Size([target_seq_len, dim_val])\n",
        "\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)  # torch.Size([target_seq_len, input_size, dim_val])\n",
        "\n",
        "        # register that pe is not a model parameter\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Tensor, shape [batch_size, enc_seq_len, dim_val]\n",
        "        \"\"\"\n",
        "\n",
        "        add = self.pe[:x.size(1), :].squeeze(1)\n",
        "\n",
        "        x = x + add\n",
        "\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfei135s7YgK",
        "outputId": "e8f4edd1-f4cd-4214-ab91-5872a56e39c4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting penc.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file utils.py\n",
        "import torch\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(dim1: int, dim2: int, dim3: int) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Generates an upper-triangular matrix of -inf, with zeros on diag.\n",
        "    Modified from:\n",
        "    https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "    Args:\n",
        "        dim1: int, batch_size * n_heads\n",
        "        dim2: int. For src and trg masking this must be target sequence length.\n",
        "        dim3: int. For src masking, this must be encoder sequence length.\n",
        "              For trg masking, this must be target sequence length\n",
        "    Return:\n",
        "        A Tensor of shape [dim1, dim2, dim3]\n",
        "    \"\"\"\n",
        "    return torch.triu(torch.ones(dim1, dim2, dim3) * float('-inf'), diagonal=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgOcUCaw7b2Y",
        "outputId": "63e8ca7c-613a-440d-802c-365936a132e5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file time_series_transformer.py\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "\n",
        "from penc import PositionalEncoder\n",
        "from config import *\n",
        "\n",
        "class TimeSeriesTransformer(nn.Module):\n",
        "    \"\"\"\n",
        "    This class implements a transformer model that can be used for times series\n",
        "    forecasting. This time series transformer model is based on the paper by\n",
        "    Wu et al (2020) [1]. The paper will be referred to as \"the paper\".\n",
        "    A detailed description of the code can be found in my article here:\n",
        "    https://towardsdatascience.com/how-to-make-a-pytorch-transformer-for-time-series-forecasting-69e073d4061e\n",
        "    In cases where the paper does not specify what value was used for a specific\n",
        "    configuration/hyperparameter, this class uses the values from Vaswani et al\n",
        "    (2017) [2] or from PyTorch source code.\n",
        "    Unlike the paper, this class assumes that input layers, positional encoding\n",
        "    layers and linear mapping layers are separate from the encoder and decoder,\n",
        "    i.e. the encoder and decoder only do what is depicted as their sub-layers\n",
        "    in the paper. For practical purposes, this assumption does not make a\n",
        "    difference - it merely means that the linear and positional encoding layers\n",
        "    are implemented inside the present class and not inside the\n",
        "    Encoder() and Decoder() classes.\n",
        "    [1] Wu, N., Green, B., Ben, X., O'banion, S. (2020).\n",
        "    'Deep Transformer Models for Time Series Forecasting:\n",
        "    The Influenza Prevalence Case'.\n",
        "    arXiv:2001.08317 [cs, stat] [Preprint].\n",
        "    Available at: http://arxiv.org/abs/2001.08317 (Accessed: 9 March 2022).\n",
        "    [2] Vaswani, A. et al. (2017)\n",
        "    'Attention Is All You Need'.\n",
        "    arXiv:1706.03762 [cs] [Preprint].\n",
        "    Available at: http://arxiv.org/abs/1706.03762 (Accessed: 9 March 2022).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 # input_size: int,\n",
        "                 dec_seq_len: int,\n",
        "                 max_seq_len: int,\n",
        "                 out_seq_len: int,\n",
        "                 dim_val: int,\n",
        "                 n_encoder_layers: int = 4,\n",
        "                 n_decoder_layers: int = 4,\n",
        "                 n_heads: int = 4,\n",
        "                 dropout_encoder: float = 0.2,\n",
        "                 dropout_decoder: float = 0.2,\n",
        "                 dropout_pos_enc: float = 0.2,\n",
        "                 dim_feedforward_encoder: int = 2048,\n",
        "                 dim_feedforward_decoder: int = 2048,\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            input_size: int, number of input variables. 1 if univariate.\n",
        "            dec_seq_len: int, the length of the input sequence fed to the decoder\n",
        "            max_seq_len: int, length of the longest sequence the model will\n",
        "                         receive. Used in positional encoding.\n",
        "            out_seq_len: int, the length of the model's output (i.e. the target\n",
        "                         sequence length)\n",
        "            dim_val: int, aka d_model. All sub-layers in the model produce\n",
        "                     outputs of dimension dim_val\n",
        "            n_encoder_layers: int, number of stacked encoder layers in the encoder\n",
        "            n_decoder_layers: int, number of stacked encoder layers in the decoder\n",
        "            n_heads: int, the number of attention heads (aka parallel attention layers)\n",
        "            dropout_encoder: float, the dropout rate of the encoder\n",
        "            dropout_decoder: float, the dropout rate of the decoder\n",
        "            dropout_pos_enc: float, the dropout rate of the positional encoder\n",
        "            dim_feedforward_encoder: int, number of neurons in the linear layer\n",
        "                                     of the encoder\n",
        "            dim_feedforward_decoder: int, number of neurons in the linear layer\n",
        "                                     of the decoder\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.dec_seq_len = dec_seq_len\n",
        "\n",
        "        # The time ranges from 0 to 23 indicating the hour of the day\n",
        "        self.time_embedding = nn.Embedding(num_embeddings=NUM_TIME, embedding_dim=TIME_EMBEDDING)\n",
        "        # the road segments ranges from 0 to ... specifying the road segments\n",
        "        self.segment_embedding = nn.Embedding(num_embeddings=NUM_SEGMENTS, embedding_dim=SEGMENT_EMBEDDING)\n",
        "        self.day_embedding = nn.Embedding(num_embeddings=NUM_DAY, embedding_dim=DAY_EMBEDDING)\n",
        "\n",
        "        # 1. create 'linear input layer' for 'encoder'\n",
        "        self.encoder_input_layer = nn.Linear(in_features=NUM_CONTINUOUS, out_features=dim_continuous)\n",
        "\n",
        "        # 2. create positional encoder\n",
        "        self.positional_encoding_layer = PositionalEncoder(d_model=dim_val,\n",
        "                                                           dropout=dropout_pos_enc,\n",
        "                                                           max_seq_len=max_seq_len)\n",
        "\n",
        "        # 3. create encoder layers using nn.TransformerDecoder\n",
        "        # The encoder layer used in the paper is identical to the one used by\n",
        "        # Vaswani et al (2017) on which the PyTorch module is based.\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_val,\n",
        "                                                   nhead=n_heads,\n",
        "                                                   dim_feedforward=dim_feedforward_encoder,\n",
        "                                                   dropout=dropout_encoder,\n",
        "                                                   batch_first=True\n",
        "                                                   )\n",
        "\n",
        "        # It seems the option of passing a normalization instance is redundant\n",
        "        # in my case, because nn.TransformerEncoderLayer per default normalizes\n",
        "        # after each sub-layer (https://github.com/pytorch/pytorch/issues/24930).\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer=encoder_layer, num_layers=n_encoder_layers, norm=None)\n",
        "\n",
        "\n",
        "        # 4. create 'linear input layer' for decoder\n",
        "        self.decoder_input_layer = nn.Linear(in_features=1, out_features=dim_val)\n",
        "\n",
        "        # 5. create decoder layers using nn.TransformerDecoder\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=dim_val,\n",
        "                                                   nhead=n_heads,\n",
        "                                                   dim_feedforward=dim_feedforward_decoder,\n",
        "                                                   dropout=dropout_decoder,\n",
        "                                                   batch_first=True\n",
        "                                                   )\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer=decoder_layer, num_layers=n_decoder_layers, norm=None)\n",
        "\n",
        "        # 6. create 'linear mapping layer'\n",
        "        self.linear_mapping = nn.Linear(in_features=dim_val, out_features=out_seq_len)\n",
        "\n",
        "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Tensor = None, tgt_mask: Tensor = None) -> Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            src: the encoder's output sequence. Shape: (S,E) for unbatched input,\n",
        "                 (S, N, E) if batch_first=False or (N, S, E) if\n",
        "                 batch_first=True, where S is the source sequence length,\n",
        "                 N is the batch size, and E is the feature number\n",
        "            tgt: the sequence to the decoder. Shape: (T,E) for unbatched input,\n",
        "                 (T, N, E)(T,N,E) if batch_first=False or (N, T, E) if\n",
        "                 batch_first=True, where T is the target sequence length,\n",
        "                 N is the batch size, E is the feature number.\n",
        "            src_mask: the mask for the src sequence to prevent the model from\n",
        "                      using data points from the target sequence\n",
        "            tgt_mask: the mask for the tgt sequence to prevent the model from\n",
        "                      using data points from the target sequence\n",
        "        \"\"\"\n",
        "        time_embedding = self.time_embedding(src[:,:,0].int())\n",
        "        day_embedding = self.day_embedding(src[:, :, 1].int())\n",
        "        segment_embedding = self.segment_embedding(src[:, :, 2].int())\n",
        "\n",
        "        src = self.encoder_input_layer(src[:,:,3:].float())\n",
        "        # concatenate them\n",
        "        src = torch.cat([time_embedding, day_embedding, segment_embedding, src], dim=2)\n",
        "        # add positional\n",
        "        src = self.positional_encoding_layer(src)\n",
        "\n",
        "        # Pass through all the stacked encoder layers in the encoder\n",
        "        # Masking is only needed in the encoder if input sequences are padded\n",
        "        # which they are not in this time series use case, because all my\n",
        "        # input sequences are naturally of the same length.\n",
        "        # (https://github.com/huggingface/transformers/issues/4083)\n",
        "        src = self.encoder(src=src)\n",
        "        decoder_output = self.decoder_input_layer(tgt.float())\n",
        "        tgt_mask = None # we are trying to keep it as simple as possible.\n",
        "        decoder_output = self.decoder(tgt=decoder_output.float(), memory=src, tgt_mask=tgt_mask, memory_mask=src_mask)\n",
        "        # print (decoder_output.shape)\n",
        "\n",
        "        decoder_output = self.linear_mapping(decoder_output)\n",
        "        # print(decoder_output.shape)\n",
        "\n",
        "        return decoder_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKqatagF7h_4",
        "outputId": "ed36e5e9-067c-4138-f843-40a4931fee0e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting time_series_transformer.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%file train.py\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from itertools import chain\n",
        "from config import *\n",
        "import numpy as np\n",
        "from time_series_transformer import TimeSeriesTransformer\n",
        "from utils import generate_square_subsequent_mask\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(data):\n",
        "    # src_trg_trgy = []\n",
        "    # for i in range(((data.shape[0] - enc_seq_len) // batch_size) * batch_size):\n",
        "    #     src = data[i:i + enc_seq_len]\n",
        "    #     trg = data[i + enc_seq_len]\n",
        "    #     trg_y = data[i + enc_seq_len - 1 + dec_seq_len: i + enc_seq_len - 1 + dec_seq_len + target_seq_len]\n",
        "    #\n",
        "    #     src = torch.FloatTensor(np.asarray(src))\n",
        "    #     trg = torch.FloatTensor(np.asarray(trg))\n",
        "    #     trg_y = torch.FloatTensor(np.asarray(trg_y))\n",
        "    #\n",
        "    #     src_trg_trgy.append((src, trg, trg_y))\n",
        "\n",
        "    # src_trg_trgy = np.array(src_trg_trgy)\n",
        "\n",
        "    # from sklearn.model_selection import ShuffleSplit\n",
        "    #\n",
        "    # sss = ShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "    # train_index, test_index = next(sss.split(src_trg_trgy))\n",
        "    #\n",
        "    # train_set = src_trg_trgy[train_index]\n",
        "    # test_set = src_trg_trgy[test_index]\n",
        "    #\n",
        "    # train_len = train_set.shape[0]\n",
        "    # test_len = test_set.shape[0]\n",
        "\n",
        "    # train = MyDataset([(src.to(device), trg.to(device), trg_y.to(device)) for src, trg, trg_y in train_set.tolist()])\n",
        "    # test = MyDataset([(src.to(device), trg.to(device), trg_y.to(device)) for src, trg, trg_y in test_set.tolist()])\n",
        "\n",
        "    train_set = DataLoader(dataset=data, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    # test_set = DataLoader(dataset=test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    # Make tgt mask for decoder with size:\n",
        "    # [batch_size*n_heads, target_seq_len, target_seq_len]\n",
        "    src_mask = None\n",
        "    tgt_mask = generate_square_subsequent_mask(dim1=n_heads * batch_size, dim2=dec_seq_len, dim3=dec_seq_len).to(DEVICE)\n",
        "\n",
        "    # -----------------------------------build model---------------------------------------------------\n",
        "    model = TimeSeriesTransformer(\n",
        "        dim_val=dim_val,\n",
        "        # input_size=input_size,\n",
        "        dec_seq_len=dec_seq_len,\n",
        "        max_seq_len=max_seq_len,\n",
        "        out_seq_len=target_seq_len,\n",
        "        n_decoder_layers=n_decoder_layers,\n",
        "        n_encoder_layers=n_encoder_layers,\n",
        "        n_heads=n_heads\n",
        "    )\n",
        "    model.to(DEVICE)\n",
        "    loss_function = nn.MSELoss().to(DEVICE)\n",
        "\n",
        "    # define optimizer\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    path = \"/content/drive/MyDrive/checkpoint.pt\"\n",
        "    path_opt = \"/content/drive/MyDrive/checkpoint_opt.pt\"\n",
        "    # -----------------------------------training---------------------------------------------------\n",
        "    loss = 0\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_model = None\n",
        "    best_optimizer = None\n",
        "    for i in range(epochs):\n",
        "        for (src, trg, trg_y) in tqdm(train_set):\n",
        "            if src.shape[0] % batch_size != 0: continue  # skip last entry\n",
        "            # The shape of src is (batchsize, seq_length, ndim)\n",
        "            # src = torch.reshape(src, (batch_size, enc_seq_len, 1))\n",
        "            # trg = torch.reshape(trg, (batch_size, dec_seq_len, 1))\n",
        "            src = src.to(DEVICE)\n",
        "            trg = trg.to(DEVICE)\n",
        "            trg_y = trg_y.to(DEVICE)\n",
        "            y_pred = model(src=src, tgt=trg, src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "            loss = loss_function(y_pred[:, -1, :].reshape(batch_size, 1), trg_y.float()).float()\n",
        "            \n",
        "            if torch.isnan(loss):\n",
        "              print(\"Loss function returned NaN, exiting\")\n",
        "              print()\n",
        "              print (trg_y, y_pred)\n",
        "              print(loss.item())\n",
        "              return\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        torch.save({\n",
        "            'epoch': i,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, path)\n",
        "        if loss < best_val_loss:\n",
        "            best_val_loss = loss\n",
        "            best_model = model\n",
        "            best_optimizer = optimizer\n",
        "            torch.save({\n",
        "            'epoch': i,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss,\n",
        "            }, path_opt)\n",
        "        print('epoch:', i, '\\tMSE:', loss.item())\n",
        "    print(\"The best loss achieved was:\", best_val_loss)\n",
        "    return None, None, best_model\n",
        "    model = best_model\n",
        "    model.eval()\n",
        "\n",
        "    pred = []\n",
        "    y = []\n",
        "    for (src, trg, trg_y) in test_set:\n",
        "        if src.shape[0] % batch_size != 0: continue  # skip last entry\n",
        "        trg_y = list(chain.from_iterable(trg_y.data.tolist()))\n",
        "        y.extend(trg_y)\n",
        "        src = torch.reshape(src, (batch_size, enc_seq_len, 1))\n",
        "        trg = torch.reshape(trg, (batch_size, dec_seq_len, 1))\n",
        "        # src = torch.reshape(src, (dec_seq_len, 1))\n",
        "        src = src.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(src=src, tgt=trg, src_mask=src_mask, tgt_mask=tgt_mask)\n",
        "            y_pred = y_pred[:, -1, :].reshape(batch_size, 1).tolist()\n",
        "            pred.extend(y_pred)\n",
        "    # test forecast results\n",
        "    test_results = np.array(pred)\n",
        "    test_real = np.array(y)\n",
        "    test_MAPE = get_mape(test_real, test_results)\n",
        "    test_RMSE = get_rmse(test_real, test_results)\n",
        "    return test_MAPE, test_RMSE, model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg9P-aoL7xUa",
        "outputId": "c9674f7f-745f-4001-852c-a719bf4c81a0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from importlib import reload\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# load data\n",
        "import pandas as pd\n",
        "import train\n",
        "from dataset import MyDataset\n",
        "df=pd.read_pickle(drive_prefix+'overall_dataframe2.pkl')\n",
        "print(df.shape)\n",
        "df=df.drop(index=df[df.day_id<700].index) # only work on data from 2022 (ish)\n",
        "print(df.shape, \"After dropping data from 2020 and 2021\")\n",
        "df.sort_values(['day_id', 'segment_id_int', 'time_window'], inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd6t4SEQR07-",
        "outputId": "c519219c-9b49-4921-a54a-61190a6ad3ae"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11555002, 13)\n",
            "(2617752, 13) After dropping data from 2020 and 2021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_50_segments = df.groupby(['day_id', 'segment_id_int'])['time_window'].count()\n"
      ],
      "metadata": {
        "id": "d6JscbQp2ovU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_50_segments = top_50_segments.groupby('segment_id_int').sum().sort_values(ascending=False).head(50)\n",
        "top_50_segments.name=\"time_window_count\""
      ],
      "metadata": {
        "id": "qqH6RaEt6UY5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGReWYFh7OAg",
        "outputId": "933015e9-ea56-4f33-b4de-95813d0ef118"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2617752, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.merge(top_50_segments, left_on=\"segment_id_int\", right_on=\"segment_id_int\").drop(columns=[\"time_window_count\"])"
      ],
      "metadata": {
        "id": "a5JTiQnW7IqH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.segment_id_int = df.segment_id_int.factorize()[0]"
      ],
      "metadata": {
        "id": "po1gFWsj7nAn"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.day_id=df.day_id.factorize()[0]"
      ],
      "metadata": {
        "id": "G_nomhuDXX9K"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dayofweek=df.dayofweek.factorize()[0]"
      ],
      "metadata": {
        "id": "s2wsm-B5XsiN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dayofweek.factorize()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lll5TuMKYbfc",
        "outputId": "ba61979f-2d5e-49d8-fbd1-e2dba45ec63c"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 0, 0, ..., 1, 1, 1]),\n",
              " Int64Index([0, 1, 2, 3, 4, 5, 6], dtype='int64'))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()  # no idea where 1 na crept up from"
      ],
      "metadata": {
        "id": "b9_w7JssZcoY"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = df.groupby(['day_id', 'segment_id_int'])['time_window'].count()\n",
        "\n",
        "buckets = {}\n",
        "i = 0\n",
        "j = 0\n",
        "for c in counts:\n",
        "  for _ in range(c-5+1):\n",
        "    buckets[j]=range(i,i+5)\n",
        "    i+=1\n",
        "    j+=1\n",
        "  i+=(5-1)"
      ],
      "metadata": {
        "id": "AOdjt5SZTmnM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
        "reload(train)\n",
        "\n",
        "dataset = MyDataset(df, buckets)\n",
        "train_df, test_df = torch.utils.data.random_split(dataset, (0.8, 0.2))\n",
        "\n",
        "# train the model. All other configurations are passed in config.py\n",
        "model = train.train(train_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "q5XYjUCZ71cj",
        "outputId": "9bfde845-1fdc-4468-bb11-437c2d71900d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 389/389 [08:20<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 \tMSE: 0.7290946245193481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 389/389 [08:22<00:00,  1.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 \tMSE: 0.7284085750579834\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 389/389 [08:16<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2 \tMSE: 0.7361782789230347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 389/389 [08:08<00:00,  1.26s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 3 \tMSE: 0.7321938276290894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 389/389 [08:03<00:00,  1.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 4 \tMSE: 0.7329614162445068\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 389/389 [08:06<00:00,  1.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 5 \tMSE: 0.7294313907623291\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 389/389 [08:12<00:00,  1.27s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 6 \tMSE: 0.7307695150375366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 389/389 [08:17<00:00,  1.28s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 7 \tMSE: 0.7311733365058899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 60/389 [01:20<07:22,  1.35s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-350c40c0d4ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# train the model. All other configurations are passed in config.py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mbest_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip last entry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m# The shape of src is (batchsize, seq_length, ndim)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuckets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         return  torch.tensor(cols[['time_window', 'dayofweek', 'segment_id_int',\n\u001b[0m\u001b[1;32m     15\u001b[0m                                    \u001b[0;34m'is_holiday'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'is_school_break'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                    \u001b[0;34m'travel_time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'darksky_temperature'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3809\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3810\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3811\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3813\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6109\u001b[0m             \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer_for\u001b[0;34m(self, target)\u001b[0m\n\u001b[1;32m   6093\u001b[0m         \"\"\"\n\u001b[1;32m   6094\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6095\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6096\u001b[0m         \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6097\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3896\u001b[0m         \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3897\u001b[0m     ) -> npt.NDArray[np.intp]:\n\u001b[0;32m-> 3898\u001b[0;31m         \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_reindex_fill_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3899\u001b[0m         \u001b[0morig_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3900\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yGgS5HgU66qX"
      }
    }
  ]
}